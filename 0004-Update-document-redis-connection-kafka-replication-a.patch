From b6f94947beaee0a29c5da93fdc21c5dc5bb8b8f0 Mon Sep 17 00:00:00 2001
From: MichaelWorkineh_git <micwor96@gmail.com>
Date: Fri, 5 Dec 2025 22:32:23 +0300
Subject: [PATCH 04/12] Update: document redis connection, kafka replication
 and robustness set

---
 docker-compose.distributed.yml                | 20 +++--
 services/document-service/index.js            | 84 +++++++++++++++----
 services/document-service/package.json        | 15 ++--
 .../document-service/src/middleware/cache.js  | 68 +++++++++++++++
 .../src/utils/kafka-producer.js               | 54 ++++++++++++
 .../document-service/src/utils/validation.js  | 43 ++++++++++
 services/shared-utils/index.js                |  7 +-
 services/shared-utils/kafka-client.js         | 23 +++++
 services/shared-utils/package.json            |  4 +-
 services/shared-utils/redis-client.js         | 30 ++++++-
 10 files changed, 312 insertions(+), 36 deletions(-)
 create mode 100644 services/document-service/src/middleware/cache.js
 create mode 100644 services/document-service/src/utils/kafka-producer.js
 create mode 100644 services/document-service/src/utils/validation.js
 create mode 100644 services/shared-utils/kafka-client.js

diff --git a/docker-compose.distributed.yml b/docker-compose.distributed.yml
index 1e66785..3bbcfd7 100644
--- a/docker-compose.distributed.yml
+++ b/docker-compose.distributed.yml
@@ -109,7 +109,7 @@ services:
       KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
       KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
       KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
-      KAFKA_MIN_INSYNC_REPLICAS: 2
+      KAFKA_MIN_INSYNC_REPLICAS: 1
       KAFKA_DEFULT_REPLICATION_FACTOR: 3
     networks:
       - distributed-network
@@ -137,7 +137,7 @@ services:
       KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
       KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
       KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
-      KAFKA_MIN_INSYNC_REPLICAS: 2
+      KAFKA_MIN_INSYNC_REPLICAS: 1
       KAFKA_DEFULT_REPLICATION_FACTOR: 3
     networks:
       - distributed-network
@@ -165,7 +165,7 @@ services:
       KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
       KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
       KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
-      KAFKA_MIN_INSYNC_REPLICAS: 2
+      KAFKA_MIN_INSYNC_REPLICAS: 1
       KAFKA_DEFULT_REPLICATION_FACTOR: 3
     networks:
       - distributed-network
@@ -194,7 +194,7 @@ services:
   redis-node-1:
     image: redis:7-alpine
     container_name: redis-node-1
-    command: redis-server --port 7001 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes
+    command: redis-server --port 7001 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes --bind 0.0.0.0 --protected-mode no
     ports:
       - "7001:7001"
     volumes:
@@ -205,7 +205,7 @@ services:
   redis-node-2:
     image: redis:7-alpine
     container_name: redis-node-2
-    command: redis-server --port 7002 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes
+    command: redis-server --port 7002 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes --bind 0.0.0.0 --protected-mode no
     ports:
       - "7002:7002"
     volumes:
@@ -216,7 +216,7 @@ services:
   redis-node-3:
     image: redis:7-alpine
     container_name: redis-node-3
-    command: redis-server --port 7003 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes
+    command: redis-server --port 7003 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes --bind 0.0.0.0 --protected-mode no
     ports:
       - "7003:7003"
     volumes:
@@ -227,7 +227,7 @@ services:
   redis-node-4:
     image: redis:7-alpine
     container_name: redis-node-4
-    command: redis-server --port 7004 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes
+    command: redis-server --port 7004 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes --bind 0.0.0.0 --protected-mode no
     ports:
       - "7004:7004"
     volumes:
@@ -238,7 +238,7 @@ services:
   redis-node-5:
     image: redis:7-alpine
     container_name: redis-node-5
-    command: redis-server --port 7005 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes
+    command: redis-server --port 7005 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes --bind 0.0.0.0 --protected-mode no
     ports:
       - "7005:7005"
     volumes:
@@ -249,7 +249,7 @@ services:
   redis-node-6:
     image: redis:7-alpine
     container_name: redis-node-6
-    command: redis-server --port 7006 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes
+    command: redis-server --port 7006 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes --bind 0.0.0.0 --protected-mode no
     ports:
       - "7006:7006"
     volumes:
@@ -404,6 +404,7 @@ services:
       - DB_REPLICA_1=postgres-replica-1
       - DB_REPLICA_2=postgres-replica-2
       - KAFKA_BROKERS=kafka-1:9092,kafka-2:9093,kafka-3:9094
+      - REDIS_NODES=redis-node-1:7001,redis-node-2:7002,redis-node-3:7003
       - JWT_SECRET=your-super-secret-jwt-key
     ports:
       - "3002:3002"
@@ -433,6 +434,7 @@ services:
       - DB_REPLICA_1=postgres-replica-1
       - DB_REPLICA_2=postgres-replica-2
       - KAFKA_BROKERS=kafka-1:9092,kafka-2:9093,kafka-3:9094
+      - REDIS_NODES=redis-node-1:7001,redis-node-2:7002,redis-node-3:7003
       - JWT_SECRET=your-super-secret-jwt-key
     ports:
       - "3012:3002"
diff --git a/services/document-service/index.js b/services/document-service/index.js
index 55c89c9..c87b781 100644
--- a/services/document-service/index.js
+++ b/services/document-service/index.js
@@ -3,6 +3,9 @@ const cors = require('cors');
 const jwt = require('jsonwebtoken');
 const { createResponse, createErrorResponse, asyncHandler, generateId, serviceRequest } = require('./shared-utils');
 const prisma = require('./shared-utils/prisma-client');
+const { validate, createDocumentSchema, updateDocumentSchema, addCollaboratorSchema } = require('./src/utils/validation');
+const { connectProducer, publishDocumentEvent } = require('./src/utils/kafka-producer');
+const { cache, invalidateCache } = require('./src/middleware/cache');
 
 const app = express();
 const PORT = process.env.PORT || 3002;
@@ -60,8 +63,8 @@ app.get('/documents', authenticateToken, asyncHandler(async (req, res) => {
   res.json(createResponse(true, documents, 'Documents retrieved successfully'));
 }));
 
-// Get specific document
-app.get('/documents/:id', authenticateToken, asyncHandler(async (req, res) => {
+// Get specific document (with caching)
+app.get('/documents/:id', authenticateToken, cache, asyncHandler(async (req, res) => {
   const { id } = req.params;
 
   const document = await prisma.document.findFirst({
@@ -90,13 +93,14 @@ app.get('/documents/:id', authenticateToken, asyncHandler(async (req, res) => {
   res.json(createResponse(true, document, 'Document retrieved successfully'));
 }));
 
-// Create new document
-app.post('/documents', authenticateToken, asyncHandler(async (req, res) => {
+// Create new document (with validation)
+app.post('/documents', authenticateToken, validate(createDocumentSchema), asyncHandler(async (req, res) => {
   const { title, content } = req.body;
+  const docId = generateId();
 
   const document = await prisma.document.create({
     data: {
-      id: generateId(),
+      id: docId,
       title: title || 'Untitled Document',
       data: content || {},
       ownerId: req.user.userId
@@ -106,11 +110,18 @@ app.post('/documents', authenticateToken, asyncHandler(async (req, res) => {
     }
   });
 
+  // Publish event
+  await publishDocumentEvent('DOCUMENT_CREATED', {
+    documentId: docId,
+    userId: req.user.userId,
+    title: document.title
+  });
+
   res.status(201).json(createResponse(true, document, 'Document created successfully'));
 }));
 
-// Update document
-app.put('/documents/:id', authenticateToken, asyncHandler(async (req, res) => {
+// Update document (with validation)
+app.put('/documents/:id', authenticateToken, validate(updateDocumentSchema), asyncHandler(async (req, res) => {
   const { id } = req.params;
   const { title, data } = req.body;
 
@@ -149,6 +160,16 @@ app.put('/documents/:id', authenticateToken, asyncHandler(async (req, res) => {
     }
   });
 
+  // Invalidate cache
+  await invalidateCache(id);
+
+  // Publish event
+  await publishDocumentEvent('DOCUMENT_UPDATED', {
+    documentId: id,
+    userId: req.user.userId,
+    updates: { title: !!title, data: !!data }
+  });
+
   res.json(createResponse(true, updatedDocument, 'Document updated successfully'));
 }));
 
@@ -173,17 +194,22 @@ app.delete('/documents/:id', authenticateToken, asyncHandler(async (req, res) =>
     where: { id }
   });
 
+  // Invalidate cache
+  await invalidateCache(id);
+
+  // Publish event
+  await publishDocumentEvent('DOCUMENT_DELETED', {
+    documentId: id,
+    userId: req.user.userId
+  });
+
   res.json(createResponse(true, null, 'Document deleted successfully'));
 }));
 
-// Add collaborator to document
-app.post('/documents/:id/collaborators', authenticateToken, asyncHandler(async (req, res) => {
+// Add collaborator to document (with validation)
+app.post('/documents/:id/collaborators', authenticateToken, validate(addCollaboratorSchema), asyncHandler(async (req, res) => {
   const { id } = req.params;
-  const { userId, role = 'editor' } = req.body;
-
-  if (!userId) {
-    return res.status(400).json(createErrorResponse('User ID is required', 400));
-  }
+  const { userId, role } = req.body;
 
   // Check if document exists and user is owner
   const document = await prisma.document.findFirst({
@@ -200,7 +226,8 @@ app.post('/documents/:id/collaborators', authenticateToken, asyncHandler(async (
   // Validate that the user to be added exists (service-to-service call)
   try {
     const authServiceUrl = process.env.AUTH_SERVICE_URL || 'http://localhost:3001';
-    await serviceRequest(`${authServiceUrl}/health`); // Basic connectivity check
+    // Use the new serviceRequest with timeout
+    await serviceRequest(`${authServiceUrl}/health`);
 
     // In a real implementation, you'd call an endpoint like /api/auth/users/:userId
     // For now, we'll assume the user exists if the ID is provided
@@ -232,6 +259,17 @@ app.post('/documents/:id/collaborators', authenticateToken, asyncHandler(async (
     }
   });
 
+  // Invalidate cache since permissions changed
+  await invalidateCache(id);
+
+  // Publish event
+  await publishDocumentEvent('COLLABORATOR_ADDED', {
+    documentId: id,
+    addedBy: req.user.userId,
+    addedUser: userId,
+    role
+  });
+
   res.status(201).json(createResponse(true, collaborator, 'Collaborator added successfully'));
 }));
 
@@ -261,6 +299,16 @@ app.delete('/documents/:id/collaborators/:userId', authenticateToken, asyncHandl
     }
   });
 
+  // Invalidate cache
+  await invalidateCache(id);
+
+  // Publish event
+  await publishDocumentEvent('COLLABORATOR_REMOVED', {
+    documentId: id,
+    removedBy: req.user.userId,
+    removedUser: userId
+  });
+
   res.json(createResponse(true, null, 'Collaborator removed successfully'));
 }));
 
@@ -270,8 +318,12 @@ app.listen(PORT, async () => {
     await prisma.$connect();
     console.log(`Document service running on port ${PORT}`);
     console.log('Connected to database successfully');
+
+    // Connect Kafka producer
+    await connectProducer();
+
   } catch (error) {
-    console.error('Failed to connect to database:', error);
+    console.error('Failed to start service:', error);
     process.exit(1);
   }
 });
diff --git a/services/document-service/package.json b/services/document-service/package.json
index 615c997..a238fe2 100644
--- a/services/document-service/package.json
+++ b/services/document-service/package.json
@@ -3,10 +3,10 @@
   "version": "1.0.0",
   "description": "Document management service for CRUD operations on documents",
   "main": "index.js",
-    "scripts": {
-      "start": "node index.js",
-      "dev": "nodemon index.js"
-    },
+  "scripts": {
+    "start": "node index.js",
+    "dev": "nodemon index.js"
+  },
   "dependencies": {
     "express": "^4.18.0",
     "cors": "^2.8.5",
@@ -14,9 +14,12 @@
     "@prisma/client": "^5.0.0",
     "prisma": "^5.0.0",
     "pg": "^8.11.0",
-    "jsonwebtoken": "^9.0.0"
+    "jsonwebtoken": "^9.0.0",
+    "joi": "^17.9.2",
+    "kafkajs": "^2.2.4",
+    "redis": "^4.6.7"
   },
   "devDependencies": {
     "nodemon": "^2.0.16"
   }
-}
+}
\ No newline at end of file
diff --git a/services/document-service/src/middleware/cache.js b/services/document-service/src/middleware/cache.js
new file mode 100644
index 0000000..3e99d9c
--- /dev/null
+++ b/services/document-service/src/middleware/cache.js
@@ -0,0 +1,68 @@
+const { createRedisClient } = require('../../shared-utils');
+
+const redisClient = createRedisClient('document-cache');
+
+// Connect to Redis
+(async () => {
+    try {
+        await redisClient.connect();
+        console.log('[Cache] Redis client connected');
+    } catch (error) {
+        console.error('[Cache] Redis connection error:', error);
+    }
+})();
+
+const CACHE_TTL = 60; // 60 seconds
+
+// Cache middleware
+const cache = async (req, res, next) => {
+    if (!redisClient.isOpen) {
+        return next();
+    }
+
+    const { id } = req.params;
+    const key = `doc:${id}`;
+
+    try {
+        const cachedData = await redisClient.get(key);
+
+        if (cachedData) {
+            console.log(`[Cache] Hit for ${key}`);
+            return res.json(JSON.parse(cachedData));
+        }
+
+        console.log(`[Cache] Miss for ${key}`);
+
+        // Intercept response to cache it
+        const originalJson = res.json;
+        res.json = function (data) {
+            if (res.statusCode === 200 && data.success) {
+                redisClient.setEx(key, CACHE_TTL, JSON.stringify(data))
+                    .catch(err => console.error('[Cache] Set error:', err));
+            }
+            return originalJson.call(this, data);
+        };
+
+        next();
+    } catch (error) {
+        console.error('[Cache] Error:', error);
+        next();
+    }
+};
+
+// Invalidate cache
+const invalidateCache = async (id) => {
+    if (!redisClient.isOpen) return;
+
+    try {
+        await redisClient.del(`doc:${id}`);
+        console.log(`[Cache] Invalidated doc:${id}`);
+    } catch (error) {
+        console.error('[Cache] Invalidation error:', error);
+    }
+};
+
+module.exports = {
+    cache,
+    invalidateCache
+};
diff --git a/services/document-service/src/utils/kafka-producer.js b/services/document-service/src/utils/kafka-producer.js
new file mode 100644
index 0000000..cea21be
--- /dev/null
+++ b/services/document-service/src/utils/kafka-producer.js
@@ -0,0 +1,54 @@
+const { createKafkaClient } = require('../../shared-utils');
+
+const instanceId = process.env.INSTANCE_ID || 'document-service';
+const kafka = createKafkaClient(instanceId);
+const producer = kafka.producer();
+
+let isConnected = false;
+
+const connectProducer = async () => {
+    let retries = 0;
+    while (!isConnected && retries < 10) {
+        try {
+            await producer.connect();
+            isConnected = true;
+            console.log(`[${instanceId}] Kafka producer connected`);
+        } catch (error) {
+            console.error(`[${instanceId}] Failed to connect Kafka producer (attempt ${retries + 1}):`, error.message);
+            retries++;
+            await new Promise(resolve => setTimeout(resolve, 5000));
+        }
+    }
+};
+
+const publishDocumentEvent = async (type, payload) => {
+    if (!isConnected) {
+        console.warn(`[${instanceId}] Kafka producer not connected, skipping event: ${type}`);
+        return;
+    }
+
+    try {
+        await producer.send({
+            topic: 'document-changes',
+            messages: [
+                {
+                    key: payload.documentId || 'unknown',
+                    value: JSON.stringify({
+                        type,
+                        timestamp: new Date().toISOString(),
+                        source: instanceId,
+                        ...payload
+                    })
+                }
+            ]
+        });
+        console.log(`[${instanceId}] Published event: ${type} for doc ${payload.documentId}`);
+    } catch (error) {
+        console.error(`[${instanceId}] Failed to publish event:`, error);
+    }
+};
+
+module.exports = {
+    connectProducer,
+    publishDocumentEvent
+};
diff --git a/services/document-service/src/utils/validation.js b/services/document-service/src/utils/validation.js
new file mode 100644
index 0000000..e3c0b2e
--- /dev/null
+++ b/services/document-service/src/utils/validation.js
@@ -0,0 +1,43 @@
+const Joi = require('joi');
+const { createErrorResponse } = require('../../shared-utils');
+
+// Schema for creating a document
+const createDocumentSchema = Joi.object({
+    title: Joi.string().trim().max(100).optional().allow(''),
+    content: Joi.alternatives().try(Joi.object(), Joi.string()).optional()
+});
+
+// Schema for updating a document
+const updateDocumentSchema = Joi.object({
+    title: Joi.string().trim().max(100).optional(),
+    data: Joi.alternatives().try(Joi.object(), Joi.string()).optional()
+});
+
+// Schema for adding a collaborator
+const addCollaboratorSchema = Joi.object({
+    userId: Joi.number().integer().required(),
+    role: Joi.string().valid('viewer', 'editor', 'owner').default('editor')
+});
+
+// Validation middleware factory
+const validate = (schema) => {
+    return (req, res, next) => {
+        const { error, value } = schema.validate(req.body, { abortEarly: false });
+
+        if (error) {
+            const errorMessage = error.details.map(detail => detail.message).join(', ');
+            return res.status(400).json(createErrorResponse(`Validation error: ${errorMessage}`, 400));
+        }
+
+        // Replace req.body with validated value (converts types if needed)
+        req.body = value;
+        next();
+    };
+};
+
+module.exports = {
+    validate,
+    createDocumentSchema,
+    updateDocumentSchema,
+    addCollaboratorSchema
+};
diff --git a/services/shared-utils/index.js b/services/shared-utils/index.js
index 300222b..0cc9000 100644
--- a/services/shared-utils/index.js
+++ b/services/shared-utils/index.js
@@ -3,6 +3,8 @@
  */
 
 const { v4: uuidv4 } = require('uuid');
+const { createRedisClient, createPubSubClients } = require('./redis-client');
+const { createKafkaClient } = require('./kafka-client');
 
 // Generate unique IDs for documents, users, etc.
 const generateId = () => {
@@ -123,5 +125,8 @@ module.exports = {
   serviceRequest,
   isValidEmail,
   hashPassword,
-  isValidPassword
+  isValidPassword,
+  createRedisClient,
+  createPubSubClients,
+  createKafkaClient
 };
diff --git a/services/shared-utils/kafka-client.js b/services/shared-utils/kafka-client.js
new file mode 100644
index 0000000..7401c9f
--- /dev/null
+++ b/services/shared-utils/kafka-client.js
@@ -0,0 +1,23 @@
+const { Kafka } = require('kafkajs');
+
+/**
+ * Create a Kafka client instance
+ * @param {string} clientId - The client ID for this service
+ * @param {string[]} brokers - List of Kafka brokers
+ */
+const createKafkaClient = (clientId, brokers) => {
+    const kafka = new Kafka({
+        clientId,
+        brokers: brokers || (process.env.KAFKA_BROKERS || 'localhost:9092').split(','),
+        retry: {
+            initialRetryTime: 100,
+            retries: 8
+        }
+    });
+
+    return kafka;
+};
+
+module.exports = {
+    createKafkaClient
+};
diff --git a/services/shared-utils/package.json b/services/shared-utils/package.json
index f2b94c0..e5f5efa 100644
--- a/services/shared-utils/package.json
+++ b/services/shared-utils/package.json
@@ -10,6 +10,8 @@
   "author": "",
   "license": "MIT",
   "dependencies": {
-    "uuid": "^9.0.0"
+    "uuid": "^9.0.0",
+    "kafkajs": "^2.2.4",
+    "redis": "^4.6.7"
   }
 }
diff --git a/services/shared-utils/redis-client.js b/services/shared-utils/redis-client.js
index 8b1adb0..5be593c 100644
--- a/services/shared-utils/redis-client.js
+++ b/services/shared-utils/redis-client.js
@@ -2,9 +2,33 @@ const redis = require('redis');
 
 // Create Redis client factory function
 const createRedisClient = (clientName = 'default') => {
-  const client = redis.createClient({
-    url: process.env.REDIS_URL || 'redis://localhost:6379'
-  });
+  let client;
+
+  if (process.env.REDIS_NODES) {
+    // Cluster mode
+    const rootNodes = process.env.REDIS_NODES.split(',').map(node => {
+      // Handle "host:port" format
+      if (!node.startsWith('redis://')) {
+        return { url: `redis://${node}` };
+      }
+      return { url: node };
+    });
+
+    console.log(`[Redis] Connecting to cluster with nodes:`, rootNodes);
+    client = redis.createCluster({
+      rootNodes,
+      defaults: {
+        socket: {
+          connectTimeout: 5000
+        }
+      }
+    });
+  } else {
+    // Standalone mode
+    client = redis.createClient({
+      url: process.env.REDIS_URL || 'redis://localhost:6379'
+    });
+  }
 
   client.on('error', (err) => console.error(`Redis Error (${clientName}):`, err));
   client.on('connect', () => console.log(`Redis connected (${clientName})`));
-- 
2.44.0.windows.1

