apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
  namespace: default
  labels:
    app: kafka
spec:
  clusterIP: None
  ports:
    - port: 9092
      name: plaintext
  selector:
    app: kafka
---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: default
  labels:
    app: kafka
spec:
  ports:
    - port: 9092
      name: plaintext
  selector:
    app: kafka
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: default
spec:
  serviceName: kafka-headless
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      initContainers:
        - name: wait-for-zookeeper
          image: busybox:1.28
          command: ['sh', '-c', "until nc -zv zookeeper 2181; do echo waiting for zookeeper; sleep 2; done"]
        - name: cleanup-stale-metadata
          image: confluentinc/cp-kafka:7.5.0
          command:
            - sh
            - -c
            - |
              echo "==> Auto-healing: Checking for stale Kafka metadata..."
              META_FILE="/var/lib/kafka/data/meta.properties"
              LOG_DIR="/var/lib/kafka/data/kafka-logs"
              
              # On any pod restart, check if we had a previous error
              # Kafka logs are in the volume, so we can check them
              if [ -d "$LOG_DIR" ] && grep -r "doesn.t match stored clusterId" "$LOG_DIR" 2>/dev/null; then
                echo "DETECTED CLUSTER ID MISMATCH in logs - Auto-healing..."
                echo "Deleting stale metadata to allow fresh registration..."
                rm -rf /var/lib/kafka/data/*
                echo "All Kafka data cleared. Kafka will start fresh."
              elif [ -f "$META_FILE" ]; then
                STORED_CLUSTER_ID=$(grep cluster.id "$META_FILE" | cut -d= -f2 || echo "")
                echo "Found existing cluster ID: $STORED_CLUSTER_ID"
                echo "Kafka will validate this on startup."
              else
                echo "No existing metadata found. This is a fresh start."
              fi
              
              echo "Init container completed successfully."
          volumeMounts:
            - name: kafka-data
              mountPath: /var/lib/kafka/data
      containers:
        - name: kafka
          image: confluentinc/cp-kafka:7.5.0
          ports:
            - containerPort: 9092
              name: plaintext
          env:
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: "zookeeper:2181"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "PLAINTEXT:PLAINTEXT"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "PLAINTEXT"
            - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
              value: "1"
            - name: KAFKA_MIN_INSYNC_REPLICAS
              value: "1"
            - name: KAFKA_DEFAULT_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_HEAP_OPTS
              value: "-Xmx512m -Xms512m"
            - name: KAFKA_LOG4J_ROOT_LOGLEVEL
              value: "INFO"
            - name: KAFKA_TOOLS_LOG4J_LOGLEVEL
              value: "INFO"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://0.0.0.0:9092"
          resources:
            requests:
              memory: "768Mi"
              cpu: "250m"
            limits:
              memory: "1.5Gi"
              cpu: "500m"
          command:
            - sh
            - -c
            - |
              # Extract the pod ordinal from the hostname (kafka-0 -> 0)
              export KAFKA_BROKER_ID=${HOSTNAME##*-}
              
              # Set advertised listeners based on the pod hostname
              export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${HOSTNAME}.kafka-headless.default.svc.cluster.local:9092
              
              # Unset KAFKA_PORT to avoid conflict with Kubernetes service env vars
              unset KAFKA_PORT

              echo "Starting Kafka with Broker ID $KAFKA_BROKER_ID and Advertised Listeners $KAFKA_ADVERTISED_LISTENERS"
              
              # Trap errors and mark for auto-healing on restart
              trap 'echo "Kafka exited with error. Checking for cluster ID mismatch..."; if grep -q "doesn.t match stored clusterId" /var/log/kafka/*.log 2>/dev/null; then touch /var/lib/kafka/data/.cluster_id_mismatch; echo "Marked for auto-healing on next restart"; fi' EXIT
              
              /etc/confluent/docker/run
          volumeMounts:
            - name: kafka-data
              mountPath: /var/lib/kafka/data
  volumeClaimTemplates:
    - metadata:
        name: kafka-data
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 1Gi
